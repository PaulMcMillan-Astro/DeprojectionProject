{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "import astropy.coordinates as coord\n",
    "import scipy.stats as st\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "from scipy.optimize import fmin_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiation of data, now loading GRD1 data and setting up the various parameters used in the code below\n",
    "\n",
    "try:\n",
    "    data_raw\n",
    "except NameError:\n",
    "    \n",
    "    data_raw = ascii.read(file, format='fast_csv')\n",
    "\n",
    "#data = data_raw[0:10000]\n",
    "    \n",
    "RA = data_raw['RAdeg']*u.degree\n",
    "DEC = data_raw['DEdeg']*u.degree\n",
    "pm_RA = data_raw['pmRA_TGAS']*u.mas/u.yr\n",
    "pm_DEC = data_raw['pmDE_TGAS']*u.mas/u.yr\n",
    "parallax = data_raw['parallax']*u.mas\n",
    "dist = data_raw['distance']*u.pc\n",
    "\n",
    "near_stars = np.where(dist.value<100)\n",
    "\n",
    "sample_raw = coord.ICRS(ra = RA, dec = DEC, pm_ra_cosdec = pm_RA, pm_dec = pm_DEC)\n",
    "\n",
    "sample = sample_raw[near_stars]\n",
    "parallax = parallax[near_stars]\n",
    "\n",
    "sample = sample.transform_to(coord.Galactic)\n",
    "\n",
    "#Oort constant values from Bovy (2018)\n",
    "A = (15.3*(u.km/(u.s*u.kpc))).to(1/u.yr)\n",
    "B = (-11.9*(u.km/(u.s*u.kpc))).to(1/u.yr)\n",
    "\n",
    "mul_obs = sample.pm_l_cosb.to(1/u.yr,equivalencies = u.dimensionless_angles())\n",
    "mub_obs = sample.pm_b.to(1/u.yr,equivalencies = u.dimensionless_angles())\n",
    "\n",
    "bvals = sample.b.to(u.deg)\n",
    "lvals = sample.l.to(u.deg)\n",
    "\n",
    "\"\"\"Computation of the relevant quantities\n",
    "\n",
    "    l,b: Galactic coordinates\n",
    "    s: the distance obtained by inverting the parallax\n",
    "    mul, mub: proper motion in l and b\n",
    "    pvals: Tangential velocities obtained from eq. 2 in DB98\n",
    "    rhatvals: The unit vector of each star\n",
    "    vmin: Vector containing the minimum velocities in v-space\n",
    "    n: The number of cells we want in each dimension of our v-space box\n",
    "    dv: Step sizes for each dimension\"\"\"\n",
    "\n",
    "b = np.deg2rad(bvals).value # just a test\n",
    "l = np.deg2rad(lvals).value\n",
    "cosl = np.cos(l)\n",
    "cosb = np.cos(b)\n",
    "sinl = np.sin(l)\n",
    "sinb = np.sin(b)\n",
    "s = parallax.to(u.kpc,equivalencies=u.parallax())\n",
    "\n",
    "mul = mul_obs - A*np.cos(2*l)-B\n",
    "mub = mub_obs + A*np.sin(2*l)*cosb*sinb\n",
    "\n",
    "pvals = s*np.array([-sinl*cosb*mul - cosl*sinb*mub,\n",
    "                 cosl*cosb*mul - sinl*sinb*mub,\n",
    "                 cosb*mub])/u.yr\n",
    "    \n",
    "rhatvals = np.array([cosb*cosl, cosb*sinl, sinb]).T\n",
    "pvals = pvals.to(u.km/u.s).value.T\n",
    "\n",
    "\"\"\"Test values for our functions\"\"\"\n",
    "\n",
    "vmin = np.array([-200,-200,-200])\n",
    "\n",
    "n = np.array([8,8,8])\n",
    "\n",
    "dv = np.array([50,50,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_K(pk,rhat,vmin,dv,n):\n",
    "    '''Calculate the values of K simultaneously for all bins for a given star with p, rhat'''\n",
    "    \n",
    "    vxmin, vymin, vzmin = vmin\n",
    "    dvx, dvy, dvz = dv\n",
    "    nx, ny, nz = n\n",
    "    pkx, pky, pkz = pk\n",
    "    rhatx, rhaty, rhatz = rhat\n",
    "    \n",
    "    K = np.zeros((nx,ny,nz))\n",
    "    \n",
    "    vxmax, vymax, vzmax = vxmin+nx*dvx,vymin+ny*dvy,vzmin+nz*dvz\n",
    "    \n",
    "    \"\"\"We now solve the line equation v = pk + vr*rhat, where v are the intersections of the line \n",
    "    and the boundaries of each bin\"\"\"\n",
    "    \n",
    "    vx_bins = np.arange(vxmin, vxmax+dvx, dvx)\n",
    "    vy_bins = np.arange(vymin, vymax+dvy, dvy)\n",
    "    vz_bins = np.arange(vzmin, vzmax+dvz, dvz)\n",
    "    \n",
    "    if np.round(np.linalg.norm(rhat))!=1:\n",
    "        raise ValueError('rhat must be a unit vector')\n",
    "    \n",
    "    vrx = (vx_bins-pkx)/rhatx\n",
    "    vry = (vy_bins-pky)/rhaty\n",
    "    vrz = (vz_bins-pkz)/rhatz\n",
    "    \n",
    "    \"\"\"After solving the line equation for each dim we remove the vr values which solve the equation\n",
    "    for bins outside of our specified box.\"\"\"\n",
    "    \n",
    "    vrmax = min(max(vrx),max(vry),max(vrz))\n",
    "    vrmin = max(min(vrx),min(vry),min(vrz))\n",
    "    \n",
    "    vrx = vrx[(vrx<=vrmax) & (vrx>=vrmin)]\n",
    "    vry = vry[(vry<=vrmax) & (vry>=vrmin)]\n",
    "    vrz = vrz[(vrz<=vrmax) & (vrz>=vrmin)]\n",
    "    vr = np.concatenate((vrx,vry,vrz))\n",
    "    vr.sort() #We obtain an ordered list with all vr values for intersections between entry and exit points\n",
    "    \n",
    "    if len(vr)==0:\n",
    "        return K\n",
    "    \n",
    "    vr_prime =(vr[:-1] + vr[1:]) / 2\n",
    "    line_bins = np.zeros((len(vr_prime),3))\n",
    "\n",
    "    pk = np.stack([pk]*len(vr_prime))\n",
    "    rhat = np.stack([rhat]*len(vr_prime))\n",
    "    vmin = np.stack([vmin]*len(vr_prime))\n",
    "    vr_primestack = np.stack([vr_prime]*3,axis=1)\n",
    "\n",
    "    \"\"\"We now solve the line equation again for values in the middle of each bin with a line segment in it.\n",
    "    This gives us the coordinates for each relevant bin, given in line_bins.\n",
    "    Finally we computhe the length of each segment and add said value to the relevant box in our K-space.\"\"\"\n",
    "    v_prime = pk + vr_primestack*rhat\n",
    "    line_bins += np.floor((v_prime-vmin)/ dv)\n",
    "      \n",
    "    line_bins = line_bins.astype(int)\n",
    "    \n",
    "    line_len = vr[1:]-vr[:-1]\n",
    "    non_zero = np.nonzero(line_len)\n",
    "    line_len = line_len[non_zero]\n",
    "    line_bins = line_bins[non_zero]\n",
    "    \n",
    "    K[line_bins[:,0],line_bins[:,1],line_bins[:,2]] = line_len/(dvx*dvy*dvz)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_sigma2(pvals,rhat):\n",
    "    \n",
    "    \"\"\"Function that applies equation 12 of DB98 for a set of stars from their tangential velocities and unit vectors.\n",
    "    Returns the velocity dispersion tensor.\"\"\"\n",
    "    \n",
    "    pmean = np.mean(pvals, axis=0)\n",
    "    \n",
    "    rhat_outer = rhat[:,:,None]*rhat[:,None,:] #Fast way of getting the outer product for each rhat with itself.\n",
    "\n",
    "    iden = np.identity(3)\n",
    "    \n",
    "    A = np.stack([iden]*len(rhat_outer))-rhat_outer #Eq. 4 in DB98. Yields an array of dim (N_star,3,3)\n",
    "    \n",
    "    A_mean = np.mean(A,axis=0)\n",
    "    A_mean_inv = np.linalg.inv(A_mean)\n",
    "    v_mean = np.dot(A_mean_inv, pmean)\n",
    "    \n",
    "    pp = pvals - np.dot(A,v_mean)\n",
    "    \n",
    "    pp2mean = np.mean(pp*pp,axis=0)\n",
    "    \n",
    "    B = np.array([[9,-1,-1],[-1,9,-1],[-1,-1,9]])\n",
    "    \n",
    "    sigma2 = (3/14)*np.dot(B,pp2mean)\n",
    "    \n",
    "    return sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nl_delta(n,l):\n",
    "    \n",
    "    \"\"\"Checks if our given vector n is within one unit vector e_i of the cell l\n",
    "    \n",
    "    First attempt at solving the problem, so can be ignored\"\"\"\n",
    "    \n",
    "    e_x = np.array([1,0,0])\n",
    "    e_y = np.array([0,1,0])\n",
    "    e_z = np.array([0,0,1])\n",
    "    \n",
    "    rules = [np.array_equal(n,l+e_x),\n",
    "            np.array_equal(n,l-e_x),\n",
    "            np.array_equal(n,l+e_y),\n",
    "            np.array_equal(n,l-e_y),\n",
    "            np.array_equal(n,l+e_z),\n",
    "            np.array_equal(n,l-e_z)]\n",
    "    \n",
    "    if np.array_equal(n,l):\n",
    "        delta = -2\n",
    "    elif any(rules):\n",
    "        delta = 1\n",
    "    else:\n",
    "        delta = 0\n",
    "    \n",
    "    return delta\n",
    "        \n",
    "def calc_xhi(line_bins,sigma2,hx,hy,hz,nx,ny,nz):\n",
    "\n",
    "    \"\"\"Given a vector l, find the estimate of the second derivative. Compare l with possible adjacent n values.\n",
    "    \n",
    "    Was also scrapped for a more efficient method sec_der\"\"\"   \n",
    "    \n",
    "    h2 = np.array([hx**2,hy**2,hz**2])\n",
    "    \n",
    "    xhi = np.zeros((len(line_bins),7))\n",
    "    \n",
    "    n_bins = np.array([nx,ny,nz])\n",
    "    \n",
    "    e_x = np.array([1,0,0])\n",
    "    e_y = np.array([0,1,0])\n",
    "    e_z = np.array([0,0,1])\n",
    "    \n",
    "    for i in range(len(line_bins)):\n",
    "        \n",
    "        l = line_bins[i]\n",
    "        \n",
    "        n_list = [l,\n",
    "                 l+e_x,l-e_x,\n",
    "                 l+e_y,l-e_y,\n",
    "                 l+e_z,l-e_z]\n",
    "        \n",
    "        print(n_list)\n",
    "        \n",
    "        for j in range(7):\n",
    "            \n",
    "            n = n_list[j]\n",
    "            \n",
    "            if (all(n>=0)) and (all(n<=n_bins)):\n",
    "                xhi[i][j] += np.sum((sigma2/h2) *  nl_delta(n,l))\n",
    "\n",
    "    return xhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sec_der(phi,sigma2,dv):\n",
    "    \n",
    "    \"\"\"Estimates the second deriative for ln(f(v_l)) given a sample of stars (eq. 30 of D98).\n",
    "    Takes contributions at the phi values of adjacent bins for each bin l.\n",
    "    \n",
    "    We create a new, larger box with dimensions n+2 centred on our phi-space box.\n",
    "    This allows us to disregard any issues at the bins at the boundaries of our phi-space.\"\"\"\n",
    "    \n",
    "    nx, ny, nz = phi.shape\n",
    "    dv2 = dv**2\n",
    "    \n",
    "    nxx, nyy, nzz = nx+2, ny+2, nz+2 \n",
    "\n",
    "    phip = np.zeros((nxx,nyy,nzz)) #new larger box\n",
    "\n",
    "    phip[1:-1,1:-1,1:-1] = phi #puts the phi-box in the centre of our larger box\n",
    "    \n",
    "    kappa = sigma2/dv2\n",
    "    \n",
    "    kappa_sum = -2*sum(sigma2/dv2)\n",
    "    \n",
    "    \"\"\"Here we compute the contributions from all the adjacent bins simultaneously.\n",
    "    In every dimension we sum the phi values of box l-1 and l+1 and multiply with the relevant factor\"\"\"\n",
    "    \n",
    "    phi_fac = np.array([phip[0:nxx-2,1:-1,1:-1]+phip[2:nxx,1:-1,1:-1],\n",
    "                           phip[1:-1,0:nyy-2,1:-1]+phip[1:-1,2:nyy,1:-1],\n",
    "                           phip[1:-1,1:-1,0:nzz-2]+phip[1:-1,1:-1,2:nzz]])\n",
    "\n",
    "    phi_arrx = (sigma2[0]/dv2[0])*phi_fac[0]\n",
    "    phi_arry = (sigma2[1]/dv2[1])*phi_fac[1]\n",
    "    phi_arrz = (sigma2[2]/dv2[2])*phi_fac[2]\n",
    "    \n",
    "    \"\"\"We sum all contributions from adjacent boxes and finally add the terms for each box l. \n",
    "    Yields a box with the same dimensions as phi, containing the second derivative values for each bin.\"\"\"\n",
    "    \n",
    "    phi_arr = phi_arrx+phi_arry+phi_arrz+kappa_sum*phi \n",
    "\n",
    "    return phi_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def phi_guess(v0,disp,vmin,dv,n):\n",
    "    \n",
    "    \"\"\"Provides an initial guess of the phi values in each bin. For now only allows for a Gaussian type guess given arrays\n",
    "    with mean velocities and dispersions for each dimension.\"\"\"\n",
    "    \n",
    "    vxmin, vymin, vzmin = vmin\n",
    "    dvx, dvy, dvz = dv\n",
    "    nx, ny, nz = n\n",
    "    v0x, v0y, v0z = v0\n",
    "    dispx, dispy, dispz = disp\n",
    "    \n",
    "    vxmax, vymax, vzmax = vxmin+nx*dvx,vymin+ny*dvy,vzmin+nz*dvz\n",
    "    \n",
    "    vx_bins = np.arange(vxmin, vxmax+dvx, dvx)\n",
    "    vy_bins = np.arange(vymin, vymax+dvy, dvy)\n",
    "    vz_bins = np.arange(vzmin, vzmax+dvz, dvz)\n",
    "    \n",
    "    vxc = (vx_bins[1:]+vx_bins[:-1])/2\n",
    "    vyc = (vy_bins[1:]+vy_bins[:-1])/2\n",
    "    vzc = (vz_bins[1:]+vz_bins[:-1])/2\n",
    "    \n",
    "    \"\"\"Given the velocities of each bin we compute the 3D Gaussian value.\"\"\"\n",
    "    \n",
    "    gx = st.norm(v0x,dispx)\n",
    "    gy = st.norm(v0y,dispy)\n",
    "    gz = st.norm(v0z,dispz)\n",
    "    \n",
    "    gxp = gx.pdf(vxc)\n",
    "    gyp = gy.pdf(vyc)\n",
    "    gzp = gz.pdf(vzc)\n",
    "    \n",
    "    phix, phiy, phiz = np.meshgrid(gxp,gyp,gzp)\n",
    "    \n",
    "    phi = np.array([phix,phiy,phiz])\n",
    "    \n",
    "    phi_sum = np.sum(phi,axis=0)\n",
    "    \n",
    "    return phi_sum.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_L(phi,*args):\n",
    "    \n",
    "    \"\"\"The function that we wish to optimise.\"\"\"\n",
    "    \n",
    "    Kvals, N, alpha, dv, n, sigma2 = args\n",
    "    nx, ny, nz = n\n",
    "    dvx, dvy, dvz = dv\n",
    "    \n",
    "    \"\"\"We regain the original shape of our phi guess and proceed to compute the various quantities needed from our functions.\"\"\"\n",
    "    \n",
    "    phi_unr = np.reshape(phi,n)\n",
    "    \n",
    "    phixhi = sec_der(phi_unr,sigma2,dv) #last term\n",
    "    \n",
    "    exphi = np.exp(phi_unr)\n",
    "    \n",
    "    Kphi = exphi*Kvals\n",
    "    \n",
    "    Kphi = Kphi.reshape(len(Kphi),nx*ny*nz) #Order all Kphi values in arrays for each star\n",
    "    \n",
    "    Kphi_sum = np.sum(Kphi,axis=1) #We compute the sum of exp(phi)*K(k|l) for each star\n",
    "    \n",
    "    notzero = Kphi_sum != 0\n",
    "    \n",
    "    Kphi_sum[notzero] = np.log(Kphi_sum[notzero]) #To make sure we don't get infinities\n",
    "    \n",
    "    Kphi_sum_tot = np.sum(Kphi_sum) #Gives the double sum in the first term\n",
    "        \n",
    "    #L_tilde = Kphi_sum_tot/N - np.sum(exphi)-(alpha/(2*dvx*dvy*dvz))*np.sum(phixhi**2)\n",
    "    L_tilde = Kphi_sum_tot/N - np.sum(exphi)-(alpha/(2*dvx*dvy*dvz))*np.sum(phixhi**2)\n",
    "    \n",
    "    negL = -1*(L_tilde+1)\n",
    "    \n",
    "    return negL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_L(alpha, pvals, rhatvals, vmin, dv, n):\n",
    "    \n",
    "    \"\"\"Function that employs scipy.optimize.fmin_cg to maximise the function get_L()\"\"\"\n",
    "    \n",
    "    thin0 = np.array([0,0,0]) #Just a guess of the Gaussian parameters\n",
    "    thin_disp  = np.array([30,100,30])\n",
    "    \n",
    "    dvx, dvy, dvz = dv\n",
    "    nx, ny, nz = n\n",
    "    \n",
    "    N = len(pvals)\n",
    "    \n",
    "    phi0 = phi_guess(thin0,thin_disp,vmin,dv,n)\n",
    "    \n",
    "    sigma2 = calc_sigma2(pvals,rhatvals)\n",
    "    \n",
    "    Kvals = np.zeros((N,nx,ny,nz))\n",
    "    \n",
    "    for i in range(N):\n",
    "        K = calc_K(pvals[i],rhatvals[i],vmin,dv,n)\n",
    "        Kvals[i] += K   \n",
    "        \n",
    "    args = (Kvals, N, alpha, dv, n, sigma2)\n",
    "    \n",
    "    phi0 = np.ravel(phi0)\n",
    "    \n",
    "    return fmin_cg(get_L, phi0, args=args)\n",
    "   \n",
    "    #return get_L(phi0, Kvals, N, alpha, dv, n, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_L(0.1, pvals, rhatvals, vmin, dv, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_sample(N): \n",
    "\n",
    "    \"\"\"A simple model star sample assuming a Gaussian velocity distribution.\"\"\"\n",
    "\n",
    "    v0 = np.array([0,0,0])\n",
    "    disp  = np.array([30,100,30])\n",
    "\n",
    "    scale = np.random.randn(N,3)\n",
    "    vel = v0 + scale*disp\n",
    "    \n",
    "    dist = np.random.rand(N)*(100-10)+10\n",
    "    \n",
    "    return psample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
