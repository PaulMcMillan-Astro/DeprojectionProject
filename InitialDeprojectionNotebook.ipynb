{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "import astropy.coordinates as coord\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "from scipy.optimize import fmin_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiation of data, now loading GRD1 data and setting up the various parameters used in the code below\n",
    "\n",
    "def load_data(file,flagset):\n",
    "    \n",
    "    data_raw = ascii.read(file, format='fast_csv')\n",
    "    \n",
    "    data = Table(data_raw, copy=True)\n",
    "    \n",
    "    if flagset == 'flag_dup':\n",
    "        \n",
    "        flag_list=['flag_dup']\n",
    "        \n",
    "    elif flagset == 'flag_any':\n",
    "        \n",
    "        flag_list=['flag_any']\n",
    "\n",
    "    elif flagset == 'flag_any-lowlogg':\n",
    "        \n",
    "        flag_list=['flag_dup','flag_N','flag_outlier','flag_pole']\n",
    "        \n",
    "    elif flagset == 'None':\n",
    "        \n",
    "        flag_list = []\n",
    "        \n",
    "    elif flagset == 'custom':\n",
    "        \n",
    "        flag_list=str(input('Tell me which flags to remove: ')).split(',')\n",
    "\n",
    "    else:\n",
    "        raise Exception('Not a valid flagset')\n",
    "    \n",
    "    bad_rows = np.array([])\n",
    "    \n",
    "    for i in flag_list:\n",
    "        \n",
    "        bad = np.nonzero(data[i])\n",
    "        \n",
    "        bad_rows = np.concatenate((bad_rows,bad[0]))\n",
    "    \n",
    "    bad_rows = np.unique(bad_rows)\n",
    "    \n",
    "    data.remove_rows(bad_rows.astype(int))\n",
    "    \n",
    "    return data,data_raw\n",
    "\n",
    "\n",
    "flagset = 'flag_any'\n",
    "\n",
    "try:\n",
    "    data\n",
    "except NameError:\n",
    "    \n",
    "    data,data_raw = load_data('Distances_PJM2017.csv',flagset)\n",
    "\n",
    "data = data_raw[0:10000]\n",
    "    \n",
    "RA = data['RAdeg']*u.degree\n",
    "DEC = data['DEdeg']*u.degree\n",
    "pm_RA = data['pmRA_TGAS']*u.mas/u.yr\n",
    "pm_DEC = data['pmDE_TGAS']*u.mas/u.yr\n",
    "parallax = data['parallax']*u.mas\n",
    "\n",
    "sample = coord.ICRS(ra = RA, dec = DEC, pm_ra_cosdec = pm_RA, pm_dec = pm_DEC)\n",
    "\n",
    "sample = sample.transform_to(coord.Galactic)\n",
    "\n",
    "#Oort constant values from Bovy (2018)\n",
    "A = (15.3*(u.km/(u.s*u.kpc))).to(1/u.yr)\n",
    "B = (-11.9*(u.km/(u.s*u.kpc))).to(1/u.yr)\n",
    "\n",
    "mul_obs = sample.pm_l_cosb.to(1/u.yr,equivalencies = u.dimensionless_angles())\n",
    "mub_obs = sample.pm_b.to(1/u.yr,equivalencies = u.dimensionless_angles())\n",
    "\n",
    "bvals = sample.b.to(u.deg)\n",
    "lvals = sample.l.to(u.deg)\n",
    "\n",
    "\"\"\"Computation of the relevant quantities\n",
    "\n",
    "    l,b: Galactic coordinates\n",
    "    s: the distance obtained by inverting the parallax\n",
    "    mul, mub: proper motion in l and b\n",
    "    pvals: Tangential velocities obtained from eq. 2 in DB98\n",
    "    rhatvals: The unit vector of each star\n",
    "    vmin: Vector containing the minimum velocities in v-space\n",
    "    n: The number of cells we want in each dimension of our v-space box\n",
    "    dv: Step sizes for each dimension\"\"\"\n",
    "\n",
    "b = np.deg2rad(bvals).value # just a test\n",
    "l = np.deg2rad(lvals).value\n",
    "cosl = np.cos(l)\n",
    "cosb = np.cos(b)\n",
    "sinl = np.sin(l)\n",
    "sinb = np.sin(b)\n",
    "s = parallax.to(u.kpc,equivalencies=u.parallax())\n",
    "\n",
    "mul = mul_obs - A*np.cos(2*l)-B\n",
    "mub = mub_obs + A*np.sin(2*l)*cosb*sinb\n",
    "\n",
    "pvals = s*np.array([-sinl*cosb*mul - cosl*sinb*mub,\n",
    "                 cosl*cosb*mul - sinl*sinb*mub,\n",
    "                 cosb*mub])/u.yr\n",
    "    \n",
    "rhatvals = np.array([cosb*cosl, cosb*sinl, sinb]).T\n",
    "pvals = pvals.to(u.km/u.s).value.T\n",
    "\n",
    "\"\"\"Test values for our functions\"\"\"\n",
    "\n",
    "#Some dispersions and mean velocities for Gaussians\n",
    "thin0 = np.array([0,215,0])\n",
    "thick0 = np.array([0,180,0])\n",
    "halo0 = np.array([0,0,0])\n",
    "thin_disp  = np.array([30,20,17])\n",
    "thick_disp  = np.array([80,60,55])\n",
    "halo_disp = np.array([160,100,100])\n",
    "\n",
    "vmin = np.array([-200,-200,-200])\n",
    "\n",
    "n = np.array([8,8,8])\n",
    "\n",
    "dv = np.array([50,50,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_K(pk,rhat,vmin,dv,n):\n",
    "    '''Calculate the values of K simultaneously for all bins for a given star with p, rhat'''\n",
    "    \n",
    "    vxmin, vymin, vzmin = vmin\n",
    "    dvx, dvy, dvz = dv\n",
    "    nx, ny, nz = n\n",
    "    pkx, pky, pkz = pk\n",
    "    rhatx, rhaty, rhatz = rhat\n",
    "    \n",
    "    K = np.zeros((nx,ny,nz))\n",
    "    \n",
    "    vxmax, vymax, vzmax = vxmin+nx*dvx,vymin+ny*dvy,vzmin+nz*dvz\n",
    "    \n",
    "    \"\"\"We now solve the line equation v = pk + vr*rhat, where v are the intersections of the line \n",
    "    and the boundaries of each bin\"\"\"\n",
    "    \n",
    "    vx_bins = np.arange(vxmin, vxmax+dvx, dvx)\n",
    "    vy_bins = np.arange(vymin, vymax+dvy, dvy)\n",
    "    vz_bins = np.arange(vzmin, vzmax+dvz, dvz)\n",
    "    \n",
    "    if np.round(np.linalg.norm(rhat))!=1:\n",
    "        raise ValueError('rhat must be a unit vector')\n",
    "    \n",
    "    vrx = (vx_bins-pkx)/rhatx\n",
    "    vry = (vy_bins-pky)/rhaty\n",
    "    vrz = (vz_bins-pkz)/rhatz\n",
    "    \n",
    "    \"\"\"After solving the line equation for each dim we remove the vr values which solve the equation\n",
    "    for bins outside of our specified box.\"\"\"\n",
    "    \n",
    "    vrmax = min(max(vrx),max(vry),max(vrz))\n",
    "    vrmin = max(min(vrx),min(vry),min(vrz))\n",
    "    \n",
    "    vrx = vrx[(vrx<=vrmax) & (vrx>=vrmin)]\n",
    "    vry = vry[(vry<=vrmax) & (vry>=vrmin)]\n",
    "    vrz = vrz[(vrz<=vrmax) & (vrz>=vrmin)]\n",
    "    vr = np.concatenate((vrx,vry,vrz))\n",
    "    vr.sort() #We obtain an ordered list with all vr values for intersections between entry and exit points\n",
    "    \n",
    "    if len(vr)==0:\n",
    "        return K\n",
    "    \n",
    "    vr_prime =(vr[:-1] + vr[1:]) / 2\n",
    "    line_bins = np.zeros((len(vr_prime),3))\n",
    "\n",
    "    pk = np.stack([pk]*len(vr_prime))\n",
    "    rhat = np.stack([rhat]*len(vr_prime))\n",
    "    vmin = np.stack([vmin]*len(vr_prime))\n",
    "    vr_primestack = np.stack([vr_prime]*3,axis=1)\n",
    "\n",
    "    \"\"\"We now solve the line equation again for values in the middle of each bin with a line segment in it.\n",
    "    This gives us the coordinates for each relevant bin, given in line_bins.\n",
    "    Finally we computhe the length of each segment and add said value to the relevant box in our K-space.\"\"\"\n",
    "    v_prime = pk + vr_primestack*rhat\n",
    "    line_bins += np.floor((v_prime-vmin)/ dv)\n",
    "      \n",
    "    line_bins = line_bins.astype(int)\n",
    "    \n",
    "    line_len = vr[1:]-vr[:-1]\n",
    "    non_zero = np.nonzero(line_len)\n",
    "    line_len = line_len[non_zero]\n",
    "    line_bins = line_bins[non_zero]\n",
    "    \n",
    "    K[line_bins[:,0],line_bins[:,1],line_bins[:,2]] = line_len/(dvx*dvy*dvz)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_sigma2(pvals,rhat):\n",
    "    \n",
    "    \"\"\"Function that applies equation 12 of DB98 for a set of stars from their tangential velocities and unit vectors.\n",
    "    Returns the velocity dispersion tensor.\"\"\"\n",
    "    \n",
    "    pmean = np.mean(pvals, axis=0)\n",
    "    \n",
    "    rhat_outer = rhat[:,:,None]*rhat[:,None,:] #Fast way of getting the outer product for each rhat with itself.\n",
    "\n",
    "    iden = np.identity(3)\n",
    "    \n",
    "    A = np.stack([iden]*len(rhat_outer))-rhat_outer #Eq. 4 in DB98. Yields an array of dim (N_star,3,3)\n",
    "    \n",
    "    A_mean = np.mean(A,axis=0)\n",
    "    A_mean_inv = np.linalg.inv(A_mean)\n",
    "    v_mean = np.dot(A_mean_inv, pmean)\n",
    "    \n",
    "    pp = pvals - np.dot(A,v_mean)\n",
    "    \n",
    "    pp2mean = np.mean(pp*pp,axis=0)\n",
    "    \n",
    "    B = np.array([[9,-1,-1],[-1,9,-1],[-1,-1,9]])\n",
    "    \n",
    "    sigma2 = (3/14)*np.dot(B,pp2mean)\n",
    "    \n",
    "    return sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nl_delta(n,l):\n",
    "    \n",
    "    \"\"\"Checks if our given vector n is within one unit vector e_i of the cell l\n",
    "    \n",
    "    First attempt at solving the problem, so can be ignored\"\"\"\n",
    "    \n",
    "    e_x = np.array([1,0,0])\n",
    "    e_y = np.array([0,1,0])\n",
    "    e_z = np.array([0,0,1])\n",
    "    \n",
    "    rules = [np.array_equal(n,l+e_x),\n",
    "            np.array_equal(n,l-e_x),\n",
    "            np.array_equal(n,l+e_y),\n",
    "            np.array_equal(n,l-e_y),\n",
    "            np.array_equal(n,l+e_z),\n",
    "            np.array_equal(n,l-e_z)]\n",
    "    \n",
    "    if np.array_equal(n,l):\n",
    "        delta = -2\n",
    "    elif any(rules):\n",
    "        delta = 1\n",
    "    else:\n",
    "        delta = 0\n",
    "    \n",
    "    return delta\n",
    "        \n",
    "def calc_xhi(line_bins,sigma2,hx,hy,hz,nx,ny,nz):\n",
    "\n",
    "    \"\"\"Given a vector l, find the estimate of the second derivative. Compare l with possible adjacent n values.\n",
    "    \n",
    "    Was also scrapped for a more efficient method sec_der\"\"\"   \n",
    "    \n",
    "    h2 = np.array([hx**2,hy**2,hz**2])\n",
    "    \n",
    "    xhi = np.zeros((len(line_bins),7))\n",
    "    \n",
    "    n_bins = np.array([nx,ny,nz])\n",
    "    \n",
    "    e_x = np.array([1,0,0])\n",
    "    e_y = np.array([0,1,0])\n",
    "    e_z = np.array([0,0,1])\n",
    "    \n",
    "    for i in range(len(line_bins)):\n",
    "        \n",
    "        l = line_bins[i]\n",
    "        \n",
    "        n_list = [l,\n",
    "                 l+e_x,l-e_x,\n",
    "                 l+e_y,l-e_y,\n",
    "                 l+e_z,l-e_z]\n",
    "        \n",
    "        print(n_list)\n",
    "        \n",
    "        for j in range(7):\n",
    "            \n",
    "            n = n_list[j]\n",
    "            \n",
    "            if (all(n>=0)) and (all(n<=n_bins)):\n",
    "                xhi[i][j] += np.sum((sigma2/h2) *  nl_delta(n,l))\n",
    "\n",
    "    return xhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sec_der(phi,sigma2,dv):\n",
    "    \n",
    "    \"\"\"Estimates the second deriative for ln(f(v_l)) given a sample of stars (eq. 30 of D98).\n",
    "    Takes contributions at the phi values of adjacent bins for each bin l.\n",
    "    \n",
    "    We create a new, larger box with dimensions n+2 centred on our phi-space box.\n",
    "    This allows us to disregard any issues at the bins at the boundaries of our phi-space.\"\"\"\n",
    "    \n",
    "    nx, ny, nz = phi.shape\n",
    "    dv2 = dv**2\n",
    "    \n",
    "    nxx, nyy, nzz = nx+2, ny+2, nz+2 \n",
    "\n",
    "    phip = np.zeros((nxx,nyy,nzz)) #new larger box\n",
    "\n",
    "    phip[1:-1,1:-1,1:-1] = phi #puts the phi-box in the centre of our larger box\n",
    "    \n",
    "    kappa = sigma2/dv2\n",
    "    \n",
    "    kappa_sum = -2*sum(sigma2/dv2)\n",
    "    \n",
    "    \"\"\"Here we compute the contributions from all the adjacent bins simultaneously.\n",
    "    In every dimension we sum the phi values of box l-1 and l+1 and multiply with the relevant factor\"\"\"\n",
    "    \n",
    "    phi_fac = np.array([phip[0:nxx-2,1:-1,1:-1]+phip[2:nxx,1:-1,1:-1],\n",
    "                           phip[1:-1,0:nyy-2,1:-1]+phip[1:-1,2:nyy,1:-1],\n",
    "                           phip[1:-1,1:-1,0:nzz-2]+phip[1:-1,1:-1,2:nzz]])\n",
    "\n",
    "    phi_arrx = (sigma2[0]/dv2[0])*phi_fac[0]\n",
    "    phi_arry = (sigma2[1]/dv2[1])*phi_fac[1]\n",
    "    phi_arrz = (sigma2[2]/dv2[2])*phi_fac[2]\n",
    "    \n",
    "    \"\"\"We sum all contributions from adjacent boxes and finally add the terms for each box l. \n",
    "    Yields a box with the same dimensions as phi, containing the second derivative values for each bin.\"\"\"\n",
    "    \n",
    "    phi_arr = phi_arrx+phi_arry+phi_arrz+kappa_sum*phi \n",
    "\n",
    "    return phi_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def phi_guess(v0,disp,vmin,dv,n):\n",
    "    \n",
    "    \"\"\"Provides an initial guess of the phi values in each bin. For now only allows for a Gaussian type guess given arrays\n",
    "    with mean velocities and dispersions for each dimension.\"\"\"\n",
    "    \n",
    "    vxmin, vymin, vzmin = vmin\n",
    "    dvx, dvy, dvz = dv\n",
    "    nx, ny, nz = n\n",
    "    \n",
    "    vxmax, vymax, vzmax = vxmin+nx*dvx,vymin+ny*dvy,vzmin+nz*dvz\n",
    "    \n",
    "    vx_bins = np.arange(vxmin, vxmax+dvx, dvx)\n",
    "    vy_bins = np.arange(vymin, vymax+dvy, dvy)\n",
    "    vz_bins = np.arange(vzmin, vzmax+dvz, dvz)\n",
    "    \n",
    "    vxc = (vx_bins[1:]+vx_bins[:-1])/2\n",
    "    vyc = (vy_bins[1:]+vy_bins[:-1])/2\n",
    "    vzc = (vz_bins[1:]+vz_bins[:-1])/2\n",
    "    \n",
    "    v0 = np.stack([v0]*len(vxc))\n",
    "    v0x = v0[:,0]\n",
    "    v0y = v0[:,1]\n",
    "    v0z = v0[:,2]\n",
    "    \n",
    "    disp = np.stack([disp]*len(vxc))\n",
    "    dispx = disp[:,0]\n",
    "    dispy = disp[:,1]\n",
    "    dispz = disp[:,2]\n",
    "    \n",
    "    \"\"\"Given the velocities of each bin we compute the 3D Gaussian value.\"\"\"\n",
    "    \n",
    "    gx = np.exp(-((vxc-v0x)**2)/(2*dispx**2)) / (dispx*np.sqrt(2*np.pi))\n",
    "    gy = np.exp(-((vyc-v0y)**2)/(2*dispy**2)) / (dispy*np.sqrt(2*np.pi))\n",
    "    gz = np.exp(-((vzc-v0z)**2)/(2*dispz**2)) / (dispz*np.sqrt(2*np.pi))\n",
    "    \n",
    "    phix, phiy, phiz = np.meshgrid(gx,gy,gz)\n",
    "    \n",
    "    phi = np.array([phix,phiy,phiz])\n",
    "    \n",
    "    phi = np.sum(phi,axis=0)\n",
    "    \n",
    "    return phi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_L(phi,*args):\n",
    "    \n",
    "    \"\"\"The function that we wish to optimise.\"\"\"\n",
    "    \n",
    "    K, N, alpha, dv, n, sigma2 = args\n",
    "    \n",
    "    dvx, dvy, dvz = dv\n",
    "    \n",
    "    phi = np.reshape(phi,n)\n",
    "    \n",
    "    phixhi = sec_der(phi,sigma2,dv)\n",
    "    \n",
    "    exphi = np.exp(phi)\n",
    "    \n",
    "    Kphi = exphi*K\n",
    "    K_sum = np.sum(np.log(Kphi),axis=0)\n",
    "        \n",
    "    L_tilde = K_sum/N + np.sum(exphi)-(alpha/(2*dvx*dvy*dvz))*np.sum(phixhi**2)\n",
    "    \n",
    "    negL = -1*(L_tilde+1)\n",
    "    \n",
    "    return negL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_L(alpha, pvals, rhatvals, vmin, dv, n):\n",
    "    \n",
    "    \"\"\"Function that employs scipy.optimize.fmin_cg to maximise the function get_L()\"\"\"\n",
    "    \n",
    "    thin0 = np.array([0,215,0]) #Just a guess of the Gaussian\n",
    "    thin_disp  = np.array([30,20,17])\n",
    "    \n",
    "    dvx, dvy, dvz = dv\n",
    "    nx, ny, nz = n\n",
    "    \n",
    "    N = len(pvals)\n",
    "    \n",
    "    phi0 = phi_guess(thin0,thin_disp,vmin,dv,n)\n",
    "    \n",
    "    sigma2 = calc_sigma2(pvals,rhatvals)\n",
    "    \n",
    "    Kvals = np.zeros((N,nx,ny,nz))\n",
    "    \n",
    "    for i in range(N):\n",
    "        K = calc_K(pvals[i],rhatvals[i],vmin,dv,n)\n",
    "        Kvals[i] += K\n",
    "        \n",
    "    args = (K, N, alpha, dv, n, sigma2)\n",
    "    \n",
    "    phi0 = np.ravel(phi0)\n",
    "    \n",
    "    #Currently dealing with an issue where fmin_cg cannot numerically estimate the gradient of our function\n",
    "    \n",
    "    fmin_cg(get_L, phi0,args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Joni\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:628: RuntimeWarning: invalid value encountered in subtract\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-371-4bb6bf197300>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax_L\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhatvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Does not work yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-370-a656049a844c>\u001b[0m in \u001b[0;36mmax_L\u001b[1;34m(alpha, pvals, rhatvals, vmin, dv, n)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#Currently dealing with an issue where fmin_cg cannot numerically estimate the gradient of our function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mfmin_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfmin_cg\u001b[1;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[0;32m   1175\u001b[0m             'return_all': retall}\n\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_cg\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[0mgrad_calls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyfprime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1228\u001b[1;33m     \u001b[0mgfk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyfprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1229\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m     \u001b[0mxk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[1;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \"\"\"\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "max_L(1, pvals, rhatvals, vmin, dv, n) #Does not work yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def max_L(phi,*args):\n",
    "    \n",
    "    #make initial guess of phi (write new phi func)\n",
    "    #maximize for these two parameters given a sample with stars using scipy.optimize.fmin_cg\n",
    "    #prosper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%timeit calc_sigma2(pvals,rhatvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
